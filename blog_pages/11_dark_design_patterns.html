<h2>Dark Design Patterns</h2>
<p>
    Rohit Chopra, the United States Federal Trade Commissioner, defines
    <a
        href="https://www.ftc.gov/system/files/documents/public_statements/1579927/172_3086_abcmouse_-_rchopra_statement.pdf">
        dark design patterns</a>
    as:
</p>
<blockquote>
    design features used to deceive, steer, or manipulate users into behavior that is profitable for an
    online service, but often harmful to users or contrary to their intent
</blockquote>

<p>
    Dark design patterns come in <a href="https://www.deceptive.design/types">16 main forms</a>:
</p>
<blockquote>
    <ol>
        <li>
            <a href="https://www.deceptive.design/types/comparison-prevention">Comparison prevention</a>:
            The user struggles to compare products because features and prices are combined in a complex
            manner, or because essential information is hard to find.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/confirmshaming">Confirmshaming</a>: The user
            is emotionally manipulated into doing something that they would not otherwise have done.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/disguised-ads">Disguised ads</a>: The user
            mistakenly believes they are clicking on an interface element or native content, but it's
            actually a disguised advertisment.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/fake-scarcity">Fake scarcity</a>: The user is
            pressured into completing an action because they are presented with a fake indication of
            limited supply or popularity.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/fake-social-proof">Fake social proof</a>: The
            user is misled into believing a product is more popular or credible than it really is,
            because they were shown fake reviews, testimonials, or activity messages.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/fake-urgency">Fake urgency</a>: The user is
            pressured into completing an action because they are presented with a fake time limitation.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/forced-action">Forced action</a>: The user wants
            to do something, but they are required to do something else undesirable in return.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/hard-to-cancel">Hard to cancel</a>: The user finds
            it easy to sign up or subscribe, but when they want to cancel they find it very hard.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/hidden-costs">Hidden Costs</a>: The user is enticed
            with a low advertised price. After investing time and effort, they discover unexpected fees and
            charges when they reach the checkout.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/hidden-subscription">Hidden subscription</a>: The user
            is unknowingly enrolled in a recurring subscription or payment plan without clear disclosure or
            their explicit consent.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/nagging">Nagging</a>: The user tries to do something,
            but they are persistently interrupted by requests to do something else that may not be in their
            best interests.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/obstruction">Obstruction</a>: The user is faced
            with barriers or hurdles, making it hard for them to complete their task or access information.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/preselection">Preselection</a>: The user is presented
            with a default option that has already been selected for them, in order to influence their
            decision-making.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/sneaking">Sneaking</a>: The user is drawn into a
            transaction on false pretences, because pertinent information is hidden or delayed from being
            presented to them.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/trick-wording">Trick wording</a>: The user is misled
            into taking an action, due to the presentation of confusing or misleading language.
        </li>

        <li>
            <a href="https://www.deceptive.design/types/visual-interference">Visual interference</a>: The
            user expects to see information presented in a clear and predictable way on the page, but it
            is hidden, obscured or disguised.
        </li>
    </ol>
</blockquote>

<h2>Dark Design Patterns and Getting Around Data Subjects' Right to Consent</h2>
<p>
    While the GDPR establishes a right to consent for data subjects, malicious implementations of user interfaces
    can be used to technically fulfill but functionally violate this right to consent. The GDPR clarifies in its
    <a href="https://gdpr-info.eu/recitals/no-32/">Recital 32</a> that consent could be achieved through 
    "ticking a box when visiting an internet website, choosing technical settings for information society services
    or another statement or conduct which clearly indicates in this context the data subject's acceptance of the
    proposed processing of his or her personal data", but these forms of consent can be manipulated by dark design
    patterns. This is mainly achieved through the use of confirmshaming, forced action, hard to cancel, nagging, obstruction, and preselection.
</p>

<p>
    A user interface may be designed to make it time consuming for a user to opt out of data
    collection. This is achieved by making it difficult to find the opt-out button or providing clealy explained
    but verbose explanations of the terms to which users will be consenting. These user interfaces may technically
    fulfill requirements for consent, but they functionally violate the right to consent by weaponizing users'
    tendencies to click through user interfaces without reading them. Users are bombarded with an immense
    number of requests for consent and explanations of terms and services, and it is extremely rare that users
    take the time to fully read the terms to which they are consenting. For example, in 2005, the company PC
    Pitstop added a clause to their End User License Agreement (EULA) that offered a $1000 cash prize to the
    first person to contact them, and it took
    <a href="https://www.pcmatic.com/blog/it-pays-to-read-license-agreements-7-years-later/">5 months and 3,000 sales
        for someone to reach out about the prize</a>.
    The GDPR provided an established right to consent for data subjects. Hwoever, the responsibility for providing 
    consent is placed on the data subject, and the GDPR does not mandate that companies take steps to ensure that
    users are truly providing fully informed consent.
</p>