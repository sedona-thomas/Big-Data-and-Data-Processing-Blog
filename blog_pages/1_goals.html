<p>
    This project is intended to contextualize mass data collection and data
    processing within a human rights frame. The main actors will be the entities
    who collect data, who sell data, who buy data, and who process data. These
    entities can be corporations, governments, or even individual people. The
    main framing of the blog will relate to privacy rights, but other concerns
    will be discussed, including the right to non-discrimination and disability
    rights.
</p>

<p>
    Specific algorithms tend to be framed as a technical problem and are often
    discussed in a manner that is not able to be fully understood by people who
    are not software engineers or computer scientists. Similarly, when discussed
    in the context of human rights, these issues are discussed at an extremely high
    level. This blog will attempt to bridge the gap between computer scientists and
    human rights advocates by analyzing both the harms, risks, and benefits of
    specific algorithms and data processing techniques.
</p>

<h2>Goals</h2>
<p>
    My main goal for this project is to stimulate normative change around the way
    artificial intelligence and machine learning are discussed with regard to human
    rights. I will be deep diving into the most prominant domains of artificial
    intelligence and machine learning with a focus on how the design of specific
    algorithms affects human rights. Throughout this blog, there will be (possibly
    interactive) demos of some of the machine learning models currently in use
    throughout the digital world.
</p>

<h2>Networks</h2>
<p>
    In order to facilitate normative change, both governmental and non-governmental
    actors will need to be mobilized. I intend to apply Price's four techniques:
</p>

<ol style="margin-left: 1%;">
    <li>Generating issues by disseminating information about specific features of
        algorithms and the human rights affected by them</li>
    <li>Establishing networks for generating broad support for change in legal data
        protections and coporate responsibility in the United states</li>
    <li>Grafting a new norm onto existing norms, specifically in relation to the
        unnecessary complexity in describing how specific algorithms work</li>
    <li>Using a transnational Socratic method to demand that companies justify their
        use of specific algorithms and data collection techniques</li>
</ol>

<small>
    All of the underlying code snippets will be available on the <a
        href="https://github.com/sedona-thomas/Big-Data-and-Data-Processing-Blog"> blog
        Github repository</a>.
</small>